{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: spacy in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\дима титаренко\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: click in c:\\users\\дима титаренко\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\дима титаренко\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<0.16.0,>=0.7.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\дима титаренко\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install  pandas spacy nltk numpy scikit-learn\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "nlp=spacy.load('ru_core_news_sm')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import SnowballStemmer\n",
    "import math\n",
    "import re\n",
    "from collections import Counter as Count\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>В конце февраля оформила кредитную карту банка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Месяц назад взял автокредит. До этого ходили п...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     Score                                               Text\n",
       "0    2  Positive  Очень порадовала оперативность работы в банке....\n",
       "1    3  Negative  Имела неосторожность оформить потреб. кредит в...\n",
       "2    4  Negative  Небольшая предыстория: Нашел на сайте MDM банк...\n",
       "3    5  Positive  В конце февраля оформила кредитную карту банка...\n",
       "4    6  Negative  Месяц назад взял автокредит. До этого ходили п..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('banks.csv',sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13997 entries, 0 to 13996\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   idx     13997 non-null  int64 \n",
      " 1   Score   13997 non-null  object\n",
      " 2   Text    13997 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 328.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13997.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4040.730194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10499.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                idx\n",
       "count  13997.000000\n",
       "mean    7000.000000\n",
       "std     4040.730194\n",
       "min        2.000000\n",
       "25%     3501.000000\n",
       "50%     7000.000000\n",
       "75%    10499.000000\n",
       "max    13998.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenizer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>Год назад брала кредит на покупку телевизора п...</td>\n",
       "      <td>[Год, брала, кредит, покупку, телевизора, деся...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>Добрый день!Являюсь владельцем кредитной карты...</td>\n",
       "      <td>[Добрый, день!Являюсь, владельцем, кредитной, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Хочу выразить свое уважение и благодарность со...</td>\n",
       "      <td>[выразить, уважение, благодарность, сотрудника...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>Часто просматриваю в интернете предложения раз...</td>\n",
       "      <td>[просматриваю, интернете, предложения, разных,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13971</th>\n",
       "      <td>Случилась у меня ситуация,- продал квартиру,по...</td>\n",
       "      <td>[Случилась, ситуация,-, продал, квартиру, поло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Хочу оставить положительный отзыв о зарплатном...</td>\n",
       "      <td>[оставить, положительный, отзыв, зарплатном, м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>Я не являюсь клиентом Альфа-Банка,но на мобиль...</td>\n",
       "      <td>[являюсь, клиентом, Альфа, Банка, мобильный, т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Добрый день.В январе пришла смс,якобы я должен...</td>\n",
       "      <td>[Добрый, день, январе, пришла, смс, банку, 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Присоединяюсь к отзыву: http://www.banki.ru/se...</td>\n",
       "      <td>[Присоединяюсь, отзыву, http://www.banki.ru/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Хотела бы рассказать о работе ДО Полянка.Отдел...</td>\n",
       "      <td>[рассказать, работе, Полянка, Отделение, работ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "4531   Год назад брала кредит на покупку телевизора п...   \n",
       "9866   Добрый день!Являюсь владельцем кредитной карты...   \n",
       "365    Хочу выразить свое уважение и благодарность со...   \n",
       "11325  Часто просматриваю в интернете предложения раз...   \n",
       "13971  Случилась у меня ситуация,- продал квартиру,по...   \n",
       "...                                                  ...   \n",
       "5191   Хочу оставить положительный отзыв о зарплатном...   \n",
       "13418  Я не являюсь клиентом Альфа-Банка,но на мобиль...   \n",
       "5390   Добрый день.В январе пришла смс,якобы я должен...   \n",
       "860    Присоединяюсь к отзыву: http://www.banki.ru/se...   \n",
       "7270   Хотела бы рассказать о работе ДО Полянка.Отдел...   \n",
       "\n",
       "                                          tokenizer_text  \n",
       "4531   [Год, брала, кредит, покупку, телевизора, деся...  \n",
       "9866   [Добрый, день!Являюсь, владельцем, кредитной, ...  \n",
       "365    [выразить, уважение, благодарность, сотрудника...  \n",
       "11325  [просматриваю, интернете, предложения, разных,...  \n",
       "13971  [Случилась, ситуация,-, продал, квартиру, поло...  \n",
       "...                                                  ...  \n",
       "5191   [оставить, положительный, отзыв, зарплатном, м...  \n",
       "13418  [являюсь, клиентом, Альфа, Банка, мобильный, т...  \n",
       "5390   [Добрый, день, январе, пришла, смс, банку, 100...  \n",
       "860    [Присоединяюсь, отзыву, http://www.banki.ru/se...  \n",
       "7270   [рассказать, работе, Полянка, Отделение, работ...  \n",
       "\n",
       "[2799 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.8, random_state=42)\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "tokens = []\n",
    "\n",
    "for text in X_train:\n",
    "    doc = nlp(text)\n",
    "    token = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    tokens.append(token)\n",
    "    \n",
    "\n",
    "df2 = pd.DataFrame({'text': X_train, 'tokenizer_text': tokens})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "data['Score'] = encoder.fit_transform(data['Score'])\n",
    "\n",
    "data['Score'] = data['Score'].map(lambda x: 1 if x=='Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9453571428571429\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\Дима Титаренко\\\\Desktop\\\\Python\\\\classification\\\\banks.csv',sep=\"\\t\")\n",
    "\n",
    "# Разделение данных на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'],data['Score'], test_size=0.2, random_state=40)\n",
    "\n",
    "# Векторизация текста с использованием TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=8000)  # можно изменить максимальное количество признаков\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Предсказание на тестовом наборе\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# # Пример данных\n",
    "# texts = [\"Текст для классификации 1\", \"Текст для классификации 2\", ...]\n",
    "# labels = [0, 1, ...]  # 0 или 1 для каждого текста\n",
    "\n",
    "# # Создание токенизатора\n",
    "# max_words = 10000  # Максимальное количество слов для учета\n",
    "# tokenizer = Tokenizer(num_words=max_words)\n",
    "# tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# # Преобразование текстов в последовательности чисел\n",
    "# sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# # Выравнивание последовательностей до одинаковой длины\n",
    "# max_sequence_length = 100  # Максимальная длина последовательности\n",
    "# data = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# # Создание модели\n",
    "# embedding_dim = 50  # Размерность пространства вложений\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "# model.add(LSTM(units=100, activation='relu'))\n",
    "# model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# # Компиляция модели\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Обучение модели\n",
    "# epochs = 5\n",
    "# batch_size = 32\n",
    "# model.fit(data, labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "# # Оценка модели\n",
    "# loss, accuracy = model.evaluate(data, labels)\n",
    "# print(f'Потери: {loss}, Точность: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = pd.read_csv('C:\\\\Users\\\\Дима Титаренко\\\\Desktop\\\\Python\\\\classification\\\\banks.csv',sep=\"\\t\")\n",
    "# # Разделение датасета на обучающий и тестовый\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# vectorizer = TfidfVectorizer(max_features=8000)  # можно изменить максимальное количество признаков\n",
    "# X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# # Создание модели\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.Input(shape=(32,32)))\n",
    "# model.add(tf.keras.layers.Dense(64, input_dim=32*32, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "# model.output_shape\n",
    "\n",
    "# # Компиляция модели\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # Обучение модели\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# # Оценка модели на тестовых данных\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10820    1\n",
       "3710     0\n",
       "3571     1\n",
       "6926     1\n",
       "6224     0\n",
       "        ..\n",
       "5191     1\n",
       "13418    0\n",
       "5390     0\n",
       "860      0\n",
       "7270     1\n",
       "Name: Score, Length: 11197, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.map(lambda x: 1 if x=='Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 1s 5ms/step - loss: 0.5082 - accuracy: 0.8649\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.2643 - accuracy: 0.9200\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1961 - accuracy: 0.9342\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 0.1680 - accuracy: 0.9425\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.9463\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.1422 - accuracy: 0.9495\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 0.1348 - accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.9536\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9540\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 0.1214 - accuracy: 0.9562\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000220859A2D40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000220859A2D40> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9407\n",
      "Loss: 0.1568070948123932, Accuracy: 0.9407142996788025\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:\\\\Users\\\\Дима Титаренко\\\\Desktop\\\\Python\\\\classification\\\\banks.csv',sep=\"\\t\")\n",
    "\n",
    "# Разделение датасета на обучающий и тестовый\n",
    "# X_train=X_train.astype('float32')\n",
    "# X_test=X_test.astype('float32')\n",
    "# y_train=y_train.astype('float32')\n",
    "# y_test=y_test.astype('float32')\n",
    "data['Score'] = data['Score'].map(lambda x: 1 if x=='Positive' else 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Score'], test_size=0.2, random_state=42)\n",
    "# y_train = y_train.map(lambda x: 1 if x=='Positive' else 0)\n",
    "# y_test = y_test.map(lambda x: 1 if x=='Positive' else 0)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1024)  \n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(32*32,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "\n",
    "model.fit(X_train_tfidf, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
